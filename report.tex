\documentclass[12pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{parskip}
\usepackage{natbib}

% Page setup
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Advanced Preprocessing Pipeline for HAR}
\fancyhead[R]{\small Machine Learning Assignment}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

% Section formatting
\titleformat{\section}{\large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.5em}{}

% Line spacing
\onehalfspacing

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=blue,
    breaklinks=true
}

% Allow URL breaks
\usepackage{xurl}

\begin{document}

% Title Page
\begin{titlepage}
    \centering
    \vspace*{2cm}
    
    {\LARGE\bfseries Advanced Preprocessing Pipeline for\\Human Activity Recognition Dataset}
    
    \vspace{0.5cm}
    {\large An Improved Approach Inspired by Recent Deep Learning Research}
    
    \vspace{2cm}
    
    {\Large\bfseries Artificial Intelligence Lab Project}
    
    \vspace{1cm}
    
    {\large Preprocessing a Numerical Dataset from a Recent ML/DL Research Paper}
    
    \vspace{2cm}
    
    \begin{tabular}{rl}
        \textbf{Student Name:} & Faisal Hakimi \\
        \textbf{Course:} & Artificial Intelligence Lab \\
        \textbf{Instructor:} & Aly Haider \\
        \textbf{Date:} & January 2026 \\
    \end{tabular}
    
    \vfill
    
    \textit{This report presents an original preprocessing pipeline implementation\\inspired by but not copied from the referenced research paper.}
    
\end{titlepage}

% Abstract
\begin{abstract}
\noindent This report presents an advanced preprocessing pipeline for the UCI Human Activity Recognition (HAR) dataset, inspired by recent deep learning research on sensor-based activity classification by Sassi Hidri et al. (2025). The implementation introduces several methodological improvements over the preprocessing techniques described in the reference paper, including Isolation Forest-based outlier detection, Savitzky-Golay signal filtering, RobustScaler normalization, and adaptive Principal Component Analysis (PCA) for dimensionality reduction. The pipeline successfully processes 10,299 sensor samples containing 561 features, achieving 95\% variance retention while reducing dimensionality by 82\%. Additionally, novel feature engineering techniques incorporating statistical moments enhance the discriminative power of the feature space. Experimental results demonstrate the effectiveness of the proposed preprocessing approach in preparing sensor data for subsequent machine learning classification tasks.

\vspace{0.3cm}
\noindent\textbf{Keywords:} Human Activity Recognition, Data Preprocessing, Outlier Detection, Signal Filtering, Dimensionality Reduction, Feature Engineering
\end{abstract}

\newpage
\tableofcontents
\newpage

% =============================================================================
\section{Paper Selection}
% =============================================================================

\subsection{Selected Research Paper}

The following research paper was selected as the reference for this preprocessing implementation:

\begin{quote}
\textbf{Title:} Enhancing Sensor-Based Human Physical Activity Recognition Using Deep Neural Networks

\textbf{Authors:} Minyar Sassi Hidri, Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, and Eman AlShehri

\textbf{Publication:} \textit{Journal of Sensor and Actuator Networks} (MDPI), Volume 14, Issue 2, Article 42

\textbf{Year:} 2025

\textbf{DOI:} \url{https://doi.org/10.3390/jsan14020042}
\end{quote}

\subsection{Justification for Paper Selection}

This paper was selected for several compelling reasons that align with the objectives of this assignment:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Recency and Relevance:} Published in 2025, the paper represents state-of-the-art research in sensor-based human activity recognition, meeting the assignment requirement for papers published between 2023--2025.
    
    \item \textbf{Comprehensive Preprocessing Discussion:} The authors provide detailed descriptions of their data preprocessing methodology, including the cleaning of noisy data, exclusion of unlabeled samples, and consistency filtering. This transparency enables meaningful comparison and improvement.
    
    \item \textbf{Numerical Dataset Focus:} The paper utilizes the WISDM dataset containing smartphone accelerometer readings---a numerical dataset with characteristics similar to the UCI HAR dataset used in this implementation.
    
    \item \textbf{Demonstrated Impact:} The paper reports that preprocessing steps removed 40,692 samples from the original 1,098,207 samples, demonstrating the significant impact of proper data preprocessing on model performance. Their optimized LSTM RNN achieves 96.1\% classification accuracy.
    
    \item \textbf{Comparable Dataset Characteristics:} Both the WISDM dataset (used in the paper) and the UCI HAR dataset (used in this implementation) share fundamental characteristics: smartphone accelerometer data, six activity classes, and time-series sensor readings.
\end{enumerate}

% =============================================================================
\section{Dataset Acquisition and Description}
% =============================================================================

\subsection{Dataset Source}

\begin{table}[H]
\centering
\caption{Dataset Information}
\label{tab:dataset_info}
\begin{tabular}{@{}p{3.5cm}p{10cm}@{}}
\toprule
\textbf{Property} & \textbf{Details} \\
\midrule
Dataset Name & Human Activity Recognition Using Smartphones \\
\addlinespace
Source & UCI Machine Learning Repository \\
\addlinespace
URL & \url{https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones} \\
\addlinespace
Data Type & Numerical (Time-series sensor readings) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Dataset Description}

The UCI Human Activity Recognition (HAR) dataset was collected from experiments conducted with 30 volunteers aged 19--48 years. Each participant performed six daily activities while wearing a Samsung Galaxy S II smartphone on their waist. The embedded accelerometer and gyroscope sensors captured 3-axial linear acceleration and 3-axial angular velocity at a constant sampling rate of 50 Hz.

The sensor signals were pre-processed by applying noise filters and sampled in fixed-width sliding windows of 2.56 seconds with 50\% overlap (128 readings per window). From each window, a feature vector was obtained by calculating variables from the time and frequency domains.

\begin{table}[H]
\centering
\caption{Dataset Statistics}
\label{tab:dataset_stats}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Property} & \textbf{Value} \\
\midrule
Total Samples & 10,299 \\
Training Samples & 7,352 \\
Test Samples & 2,947 \\
Number of Features & 561 \\
Number of Classes & 6 \\
Sampling Rate & 50 Hz \\
Window Size & 2.56 seconds \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Activity Classes}

The dataset contains six activity classes representing common daily activities, as shown in Table~\ref{tab:activity_dist}.

\begin{table}[H]
\centering
\caption{Activity Class Distribution in the UCI HAR Dataset}
\label{tab:activity_dist}
\begin{tabular}{@{}clcc@{}}
\toprule
\textbf{Label} & \textbf{Activity} & \textbf{Samples} & \textbf{Percentage} \\
\midrule
1 & Walking & 1,722 & 16.7\% \\
2 & Walking Upstairs & 1,544 & 15.0\% \\
3 & Walking Downstairs & 1,406 & 13.7\% \\
4 & Sitting & 1,777 & 17.3\% \\
5 & Standing & 1,906 & 18.5\% \\
6 & Laying & 1,944 & 18.9\% \\
\midrule
& \textbf{Total} & \textbf{10,299} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Suitability for Preprocessing Experimentation}

The UCI HAR dataset is particularly suitable for preprocessing experimentation due to the following characteristics:

\begin{itemize}[leftmargin=*]
    \item \textbf{High Dimensionality:} With 561 features, the dataset provides an excellent testbed for dimensionality reduction techniques such as PCA.
    
    \item \textbf{Real Sensor Data:} The dataset contains actual accelerometer and gyroscope readings with inherent sensor noise, making it ideal for evaluating signal filtering techniques.
    
    \item \textbf{Benchmark Status:} As a widely-used benchmark in the HAR research community, results can be compared with numerous published studies.
    
    \item \textbf{Multi-class Classification:} The six activity classes enable evaluation of preprocessing impact on classification performance across different activity types.
    
    \item \textbf{Time-series Nature:} The sequential nature of sensor data allows for the application of temporal preprocessing techniques such as signal filtering.
\end{itemize}

% =============================================================================
\section{Preprocessing Implementation}
% =============================================================================

This section presents the complete preprocessing pipeline, consisting of eight sequential steps. Each step is designed to improve data quality for downstream machine learning tasks while addressing specific challenges in sensor data processing.

\subsection{Step 1: Data Loading}

The preprocessing pipeline begins with loading the UCI HAR dataset from the extracted directory structure. The dataset is provided in space-separated text files, with feature names stored in a separate file.

\textbf{Implementation Details:}
\begin{itemize}[leftmargin=*]
    \item Feature names are loaded from \texttt{features.txt} and made unique by appending indices to duplicate names (the original dataset contains 42 duplicate feature names).
    \item Training and test sets are combined for comprehensive preprocessing, ensuring consistent transformations across all data.
    \item The combined dataset contains 10,299 samples with 561 features.
\end{itemize}

\subsection{Step 2: Missing Value Handling}

\textbf{Method:} Hybrid Forward-Fill with Mean Imputation

\textbf{Justification:} For time-series sensor data, temporal continuity is an important characteristic that should be preserved during imputation. The hybrid approach implements a three-stage strategy:

\begin{enumerate}
    \item \textbf{Forward-fill interpolation:} Propagates the last valid observation forward, preserving temporal patterns in sequential data.
    \item \textbf{Backward-fill:} Handles edge cases where forward-fill cannot be applied (e.g., missing values at the beginning of sequences).
    \item \textbf{Mean imputation:} Serves as a final fallback for any remaining missing values.
\end{enumerate}

\textbf{Improvement over Reference Paper:} The reference paper by Sassi Hidri et al. employs exclusion of samples with missing or invalid labels. Our hybrid approach attempts to preserve data by imputing values, which is more appropriate when data collection is expensive or limited.

\textbf{Result:} The UCI HAR dataset contained 0 missing values (pre-cleaned), but the robust pipeline ensures handling of any missing data scenarios.

\subsection{Step 3: Outlier Detection and Removal}

\textbf{Method:} Isolation Forest with IQR-based Capping

\textbf{Justification:} Isolation Forest was selected for outlier detection due to its effectiveness with high-dimensional data. Unlike traditional methods such as Z-score, Isolation Forest:

\begin{itemize}[leftmargin=*]
    \item Does not assume any particular data distribution
    \item Handles high-dimensional feature spaces (561 features) effectively
    \item Detects complex, multivariate outlier patterns
    \item Is computationally efficient with $O(n \log n)$ complexity
\end{itemize}

\textbf{Parameters:}
\begin{itemize}[leftmargin=*]
    \item Contamination rate: 5\% (expected proportion of outliers)
    \item Number of estimators: 100 trees
    \item IQR multiplier: 1.5 for extreme value capping
\end{itemize}

\textbf{Improvement over Reference Paper:} The reference paper mentions removing ``extreme outliers'' and ``implausible accelerometer readings'' without specifying a systematic method. Our Isolation Forest approach provides a principled, machine learning-based outlier detection that is reproducible and well-documented.

\textbf{Results:}
\begin{itemize}[leftmargin=*]
    \item Outliers detected and removed: 515 samples (5.00\%)
    \item Clean samples retained: 9,784
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{00_outlier_detection.png}
    \caption{Outlier detection results using Isolation Forest. The top row displays the original data with detected outliers highlighted in red, while the bottom row shows the cleaned dataset after outlier removal. Three representative features are shown: tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z. The visualization demonstrates the effectiveness of Isolation Forest in identifying anomalous sensor readings that deviate significantly from the normal data distribution.}
    \label{fig:outlier_detection}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{00b_outlier_boxplot.png}
    \caption{Box plot comparison of feature distributions before and after outlier removal. The left panel shows the original data distribution with visible outliers extending beyond the whiskers, while the right panel displays the cleaned data with reduced variance and more compact distributions. This comparison illustrates how the combination of Isolation Forest detection and IQR-based capping effectively reduces the influence of extreme values while preserving the underlying data structure.}
    \label{fig:outlier_boxplot}
\end{figure}

\subsection{Step 4: Signal Filtering and Denoising}

\textbf{Method:} Savitzky-Golay Filter

\textbf{Justification:} This step represents a \textbf{novel addition} not explicitly present in the reference paper. The Savitzky-Golay filter is a digital filter that performs polynomial smoothing, offering several advantages for sensor data:

\begin{itemize}[leftmargin=*]
    \item Removes high-frequency sensor noise while preserving signal features
    \item Maintains the shape and height of waveform peaks
    \item Preserves higher moments of the signal (unlike simple moving average)
    \item Does not introduce phase shift in the filtered signal
\end{itemize}

\textbf{Parameters:}
\begin{itemize}[leftmargin=*]
    \item Window length: 11 samples
    \item Polynomial order: 3
    \item Applied to first 100 time-domain features
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{01_signal_filtering_comparison.png}
    \caption{Comparison of sensor signals before and after Savitzky-Golay filtering. Each subplot displays a different feature, with the original noisy signal shown in light color and the filtered signal overlaid in darker color. The filter effectively smooths high-frequency noise while preserving the underlying signal patterns, trends, and important features such as peaks and valleys. This preprocessing step is particularly beneficial for accelerometer data where sensor noise can obscure meaningful activity patterns.}
    \label{fig:signal_filtering}
\end{figure}

\subsection{Step 5: Feature Scaling and Normalization}

\textbf{Method:} RobustScaler

\textbf{Justification:} RobustScaler was chosen over StandardScaler for the following reasons:

\begin{itemize}[leftmargin=*]
    \item Uses median and interquartile range (IQR) instead of mean and standard deviation
    \item More robust to remaining outliers after the cleaning step
    \item Better suited for sensor data with heavy-tailed distributions
    \item Preserves relative feature importance
\end{itemize}

The transformation is defined as:
\begin{equation}
    x_{scaled} = \frac{x - \text{median}(x)}{\text{IQR}(x)}
\end{equation}

\textbf{Improvement over Reference Paper:} The reference paper mentions label encoding but does not detail feature scaling methodology. Our RobustScaler approach provides comprehensive normalization that is robust to outliers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{02_feature_scaling_comparison.png}
    \caption{Feature scaling effect using RobustScaler. The left panel shows the original feature distributions with varying scales and ranges, while the right panel displays the scaled features centered around zero with standardized spread. RobustScaler uses median and IQR for scaling, making it more resistant to outliers compared to StandardScaler. This normalization ensures that all features contribute equally to subsequent machine learning algorithms regardless of their original measurement scales.}
    \label{fig:scaling}
\end{figure}

\subsection{Step 6: Dimensionality Reduction}

\textbf{Method:} Principal Component Analysis (PCA) with Adaptive Component Selection

\textbf{Justification:} Rather than using a fixed number of components, an adaptive approach based on variance retention was implemented:

\begin{itemize}[leftmargin=*]
    \item Target: Retain 95\% of total variance
    \item Data-driven component selection ensures optimal dimensionality
    \item Removes noise and redundancy in the feature space
    \item Reduces computational complexity for downstream tasks
\end{itemize}

\textbf{Improvement over Reference Paper:} The reference paper relies on deep learning architectures (CNN, LSTM) for automatic feature extraction without explicit dimensionality reduction. Our PCA approach reduces computational complexity while retaining 95\% of information, making it suitable for both traditional ML and DL models.

\textbf{Results:}
\begin{itemize}[leftmargin=*]
    \item Original features: 561
    \item PCA components: 100
    \item Variance explained: 95.00\%
    \item Dimensionality reduction: 82.2\%
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{03_pca_analysis.png}
    \caption{Principal Component Analysis results. Top-left: Individual explained variance ratio for the first 20 principal components, showing that the first few components capture the majority of variance. Top-right: Cumulative explained variance curve with the 95\% threshold marked, indicating that 100 components are sufficient to retain 95\% of the total variance. Bottom-left: Scatter plot of the first two principal components colored by activity class, revealing some natural clustering of activities in the reduced feature space. Bottom-right: Bar chart comparing the original 561 features to the 100 PCA components, illustrating the 82.2\% reduction in dimensionality.}
    \label{fig:pca}
\end{figure}

\subsection{Step 7: Train-Test Split}

\textbf{Method:} Stratified Random Split

\textbf{Configuration:}
\begin{itemize}[leftmargin=*]
    \item Split ratio: 80\% training, 20\% testing
    \item Stratification: Enabled (maintains class distribution)
    \item Random state: 42 (for reproducibility)
\end{itemize}

\textbf{Justification:}
\begin{itemize}[leftmargin=*]
    \item The 80-20 split is standard for datasets with 1,000--10,000 samples
    \item Stratification ensures balanced class distribution in both sets
    \item Maintains activity representation proportionally in training and test sets
    \item Provides sufficient test samples for reliable performance evaluation
\end{itemize}

\textbf{Results:}
\begin{itemize}[leftmargin=*]
    \item Training set: 7,827 samples (80.0\%)
    \item Test set: 1,957 samples (20.0\%)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{04_train_test_distribution.png}
    \caption{Activity class distribution in training and test sets after stratified splitting. Both panels show the number of samples per activity class, demonstrating that the stratified split successfully maintains the original class proportions in both subsets. This balanced distribution is crucial for training unbiased classifiers and obtaining reliable performance estimates on the test set.}
    \label{fig:train_test}
\end{figure}

\subsection{Step 8: Feature Engineering}

\textbf{Method:} Statistical Moment Features

\textbf{Justification:} This step represents another \textbf{novel addition} that complements the reference paper's approach. While Sassi Hidri et al. rely on deep learning for automatic feature learning, we add explicit statistical features that can enhance both traditional ML and DL models:

\begin{itemize}[leftmargin=*]
    \item \textbf{Skewness:} Captures distribution asymmetry across principal components
    \item \textbf{Kurtosis:} Captures distribution tail behavior and peakedness
    \item \textbf{Maximum value:} Captures signal amplitude upper bound
    \item \textbf{Minimum value:} Captures signal amplitude lower bound
    \item \textbf{Range:} Captures signal amplitude span (max - min)
\end{itemize}

\textbf{Benefits:}
\begin{itemize}[leftmargin=*]
    \item Captures distribution shape information not explicitly present in PCA components
    \item Distinguishes between activity patterns based on signal characteristics
    \item Enhances pattern recognition capability
    \item Adds discriminative power for classification tasks
\end{itemize}

\textbf{Results:}
\begin{itemize}[leftmargin=*]
    \item Features after PCA: 100
    \item Features after engineering: 105 (+5 new features)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{05_feature_engineering.png}
    \caption{Distribution of engineered statistical features across activity classes. Each subplot shows box plots of a specific engineered feature (skewness, kurtosis, max, min, range) for all six activity classes. The varying distributions across activities demonstrate that these statistical moments capture discriminative information that can help distinguish between different physical activities. For example, dynamic activities (walking, stairs) show different range and kurtosis patterns compared to static activities (sitting, standing, laying).}
    \label{fig:feature_eng}
\end{figure}

% =============================================================================
\section{Comparison with Reference Paper}
% =============================================================================

Table~\ref{tab:comparison} presents a comprehensive comparison between the preprocessing methods described in the reference paper and our improved implementation.

\begin{table}[H]
\centering
\caption{Comparison of Preprocessing Methods: Reference Paper vs. Our Implementation}
\label{tab:comparison}
\begin{tabular}{@{}p{2.8cm}p{4cm}p{4cm}p{3.5cm}@{}}
\toprule
\textbf{Aspect} & \textbf{Reference Paper} & \textbf{Our Implementation} & \textbf{Improvement} \\
\midrule
Missing Values & Exclusion of samples with missing/invalid labels & Hybrid forward-fill + mean imputation & Preserves more data \\
\addlinespace
Outlier Detection & Manual removal of extreme outliers & Isolation Forest + IQR capping & Systematic ML-based approach \\
\addlinespace
Signal Processing & Not explicitly mentioned & Savitzky-Golay filter & \textbf{Novel:} Noise removal \\
\addlinespace
Feature Scaling & Label encoding only & RobustScaler normalization & Comprehensive scaling \\
\addlinespace
Dimensionality Reduction & Not applied (relies on DL) & Adaptive PCA (95\% variance) & \textbf{Novel:} Reduces complexity \\
\addlinespace
Feature Engineering & Automatic via DL & Statistical moments (5 features) & \textbf{Novel:} Explicit features \\
\addlinespace
Data Split & Train-test separation & Stratified 80-20 split & Balanced distribution \\
\bottomrule
\end{tabular}
\end{table}

% =============================================================================
\section{Pipeline Summary}
% =============================================================================

Table~\ref{tab:pipeline_summary} summarizes the data transformation through each step of the preprocessing pipeline.

\begin{table}[H]
\centering
\caption{Data Transformation Through the Preprocessing Pipeline}
\label{tab:pipeline_summary}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Pipeline Step} & \textbf{Samples} & \textbf{Features} \\
\midrule
1. Original Dataset & 10,299 & 561 \\
2. After Missing Value Handling & 10,299 & 561 \\
3. After Outlier Removal & 9,784 & 561 \\
4. After Signal Filtering & 9,784 & 561 \\
5. After Feature Scaling & 9,784 & 561 \\
6. After PCA & 9,784 & 100 \\
7. After Feature Engineering & 9,784 & 105 \\
\midrule
Final Training Set & 7,827 & 105 \\
Final Test Set & 1,957 & 105 \\
\bottomrule
\end{tabular}
\end{table}

% =============================================================================
\section{Code Implementation}
% =============================================================================

The complete preprocessing pipeline was implemented in Python using the following libraries:

\begin{itemize}[leftmargin=*]
    \item \texttt{pandas} (v2.0+): Data manipulation and analysis
    \item \texttt{numpy} (v1.24+): Numerical computations
    \item \texttt{scikit-learn} (v1.3+): Machine learning utilities (PCA, RobustScaler, IsolationForest, train\_test\_split)
    \item \texttt{scipy} (v1.11+): Signal processing (Savitzky-Golay filter)
    \item \texttt{matplotlib} (v3.7+): Data visualization
\end{itemize}

The code is well-documented with comments explaining each preprocessing step. Key functions include:

\begin{itemize}[leftmargin=*]
    \item \texttt{cap\_outliers\_iqr()}: Implements IQR-based outlier capping
    \item \texttt{add\_statistical\_moments()}: Computes and adds statistical features
\end{itemize}

\textbf{Output Files Generated:}
\begin{itemize}[leftmargin=*]
    \item \texttt{X\_train\_preprocessed.csv}: Preprocessed training features (7,827 × 105)
    \item \texttt{X\_test\_preprocessed.csv}: Preprocessed test features (1,957 × 105)
    \item \texttt{y\_train.csv}: Training labels (7,827 samples)
    \item \texttt{y\_test.csv}: Test labels (1,957 samples)
    \item 6 visualization files in PNG format (300 DPI)
\end{itemize}

% =============================================================================
\section{Conclusion}
% =============================================================================

This report presented an advanced preprocessing pipeline for the UCI Human Activity Recognition dataset that extends and improves upon the preprocessing methodology described by Sassi Hidri et al. (2025). The key contributions of this work include:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Systematic Outlier Detection:} Implementation of Isolation Forest provides a principled, machine learning-based approach to outlier detection, compared to the manual removal described in the reference paper.
    
    \item \textbf{Signal Denoising:} Introduction of Savitzky-Golay filtering as a novel preprocessing step that removes high-frequency sensor noise while preserving important signal characteristics.
    
    \item \textbf{Adaptive Dimensionality Reduction:} Application of PCA with a 95\% variance retention threshold reduces the feature space from 561 to 100 dimensions, decreasing computational complexity while maintaining information content.
    
    \item \textbf{Explicit Feature Engineering:} Addition of statistical moment features (skewness, kurtosis, range) complements the automatic feature learning approach used in the reference paper.
\end{enumerate}

The pipeline successfully processes the UCI HAR dataset, reducing 561 features to 105 while retaining 95\% of variance, removing 5\% outliers using a principled approach, and producing clean, normalized data ready for machine learning model training. The preprocessed data can serve as input to the deep learning architectures (CNN, LSTM) proposed in the reference paper, potentially improving their reported 96.1\% classification accuracy.

% =============================================================================
% References
% =============================================================================
\newpage
\section*{References}
\addcontentsline{toc}{section}{References}

\begin{enumerate}[leftmargin=*]
    \item Sassi Hidri, M., Hidri, A., Alsaif, S. A., Alahmari, M., \& AlShehri, E. (2025). Enhancing Sensor-Based Human Physical Activity Recognition Using Deep Neural Networks. \textit{Journal of Sensor and Actuator Networks}, 14(2), Article 42. \url{https://doi.org/10.3390/jsan14020042}
    
    \item Anguita, D., Ghio, A., Oneto, L., Parra, X., \& Reyes-Ortiz, J. L. (2013). A Public Domain Dataset for Human Activity Recognition Using Smartphones. \textit{Proceedings of the 21st European Symposium on Artificial Neural Networks (ESANN)}, Bruges, Belgium.
    
    \item UCI Machine Learning Repository. Human Activity Recognition Using Smartphones Dataset. Retrieved from \url{https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones}
    
    \item WISDM Lab. Wireless Sensor Data Mining. Fordham University. Retrieved from \url{https://www.cis.fordham.edu/wisdm/dataset.php}
    
    \item Liu, F. T., Ting, K. M., \& Zhou, Z. H. (2008). Isolation Forest. \textit{Proceedings of the 8th IEEE International Conference on Data Mining (ICDM)}, 413--422.
    
    \item Savitzky, A., \& Golay, M. J. (1964). Smoothing and Differentiation of Data by Simplified Least Squares Procedures. \textit{Analytical Chemistry}, 36(8), 1627--1639.
\end{enumerate}

\end{document}
